# ============================================================
# chatbot_controller.py - Duarte Grilo 2201320 - Projeto InformÃ¡tico
# ============================================================
# Este mÃ³dulo Ã© responsÃ¡vel por:
# ğŸ”¹ Coordenar o ciclo completo de interaÃ§Ã£o com o utilizador
# ğŸ”¹ Integrar os mÃ³dulos de:
#     - RecuperaÃ§Ã£o de contexto (RAG com ChromaDB)
#     - TraduÃ§Ã£o bidirecional (PT âœ EN âœ PT)
#     - GeraÃ§Ã£o de resposta com Velvet-2B
#     - ValidaÃ§Ã£o automÃ¡tica por palavras-chave
# ğŸ”¹ Exibir mÃ©tricas de resposta (tokens, tempo, validaÃ§Ã£o)
# ğŸ”¹ Guardar a interaÃ§Ã£o completa:
#     - Em histÃ³rico (velvet_respostas.json)
#     - Em ficheiro temporÃ¡rio com a Ãºltima resposta (velvet_ultima_resposta.json)
#     - Em ficheiro de mÃ©tricas (velvet_metrics.jsonl)
#     - Em ficheiro de logs tÃ©cnicos (velvet_logs.txt)
# ============================================================

import time
import re
from models.velvet_runner import generate_response, salvar_completo_em_arquivo  # GeraÃ§Ã£o e gravaÃ§Ã£o
from models.rag_engine import retrieve_context                         # Busca com RAG
from models.tradutor_local import traduzir                             # TraduÃ§Ã£o PT/EN
from datetime import datetime

from controllers.logger import salvar_metricas, log_evento  # <--- NOVO IMPORT

# Conta tokens de um texto (simples split por espaÃ§o)


def contar_tokens(texto: str) -> int:
    return len(texto.split())

# Valida se a resposta contÃ©m palavras-chave do contexto


def validar_resposta_por_keywords(resposta: str, contexto: str, min_match: int = 3) -> tuple[bool, int]:
    palavras_contexto = re.findall(r'\b\w{4,}\b', contexto.lower())
    palavras_resposta = re.findall(r'\b\w{4,}\b', resposta.lower())
    comuns = set(palavras_contexto).intersection(set(palavras_resposta))
    return len(comuns) >= min_match, len(comuns)

# FunÃ§Ã£o principal que processa cada pergunta


def process_user_input(question: str) -> str:
    log_evento(f"Pergunta recebida: {question}")

    print("\nğŸ” [DEBUG] Entrou em process_user_input()")
    print(f"ğŸ” [DEBUG] Pergunta recebida: {question}")

    # ObtÃ©m contexto, scores e dados brutos com debug incluÃ­do
    context_pt, scores, context_en, context_norm, debug_ctx = retrieve_context(
        question, return_scores=True, return_raw=True
    )

    print(f"\nğŸ“š [DEBUG] Contexto traduzido (PT, inÃ­cio): {context_pt[:120]}...")

    # Traduz a pergunta para inglÃªs
    question_en = traduzir(question, origem='pt', destino='en')

    # Cria prompt final a ser enviado ao Velvet
    prompt_en = f"Context:\n{debug_ctx['context_en']}\n\nQuestion: {question_en}\nAnswer:"
    print(f"\nğŸ§  [DEBUG] Prompt final (EN) enviado Ã  Velvet:\n{prompt_en}\n")

    # Mede tempo de geraÃ§Ã£o
    inicio = time.time()
    resposta_en = generate_response(prompt_en)
    duracao = time.time() - inicio

    print(f"\nğŸ’¬ [DEBUG] Resposta bruta (EN) gerada pelo Velvet:\n{resposta_en.strip()}")

    # Tenta traduzir de volta para portuguÃªs
    try:
        resposta_final = traduzir(resposta_en.strip(), origem="en", destino="pt")
    except Exception as e:
        print("âš ï¸ Erro na traduÃ§Ã£o da resposta:", e)
        resposta_final = resposta_en.strip()

    # ValidaÃ§Ã£o da resposta com palavras-chave
    valido, num_keywords = validar_resposta_por_keywords(resposta_final, context_pt)
    if not valido or len(resposta_final) < 10:
        resposta_final = "âš ï¸ NÃ£o foi possÃ­vel gerar uma resposta adequada com base no contexto."

    # Exibe mÃ©tricas no terminal
    print("\nğŸ“Š [MÃ‰TRICAS DE RESPOSTA]")
    print(f"ğŸ”¸ Prompt Tokens:        {contar_tokens(prompt_en)}")
    print(f"ğŸ”¸ Resposta Tokens:      {contar_tokens(resposta_en)}")
    print(f"ğŸ”¸ Tempo de geraÃ§Ã£o:     {duracao:.2f}s")
    print(f"ğŸ”¸ Palavras-chave comuns: {num_keywords}")
    print(f"ğŸ”¸ ValidaÃ§Ã£o por keywords: {'âœ…' if valido else 'âŒ'}")

    # Mostra documentos usados com suas pontuaÃ§Ãµes
    print("\nğŸ”¸ Similaridade RAG:")
    for i, (trecho, score) in enumerate(scores, start=1):
        preview = trecho.page_content[:80].replace("\n", " ")
        print(f"    Doc#{i}: score={score:.2f} âœ {preview}...")

    # Guarda mÃ©tricas em ficheiro prÃ³prio
    salvar_metricas({
        "pergunta": question,
        "tempo_execucao": round(duracao, 2),
        "prompt_tokens": contar_tokens(prompt_en),
        "resposta_tokens": contar_tokens(resposta_en),
        "palavras_chave_comuns": num_keywords,
        "validacao_keywords": valido
    })

    # Log tÃ©cnico detalhado
    log_evento(f"Processada pergunta: {question} | Tokens: {contar_tokens(prompt_en)} prompt, {contar_tokens(resposta_en)} resposta | Tempo: {duracao:.2f}s | ValidaÃ§Ã£o: {valido}")

    # Guarda tudo no histÃ³rico local com estrutura completa
    salvar_completo_em_arquivo({
        "pergunta_original": question,
        "contexto_pt": context_pt,
        "prompt_enviado": prompt_en,
        "resposta_en": resposta_en.strip(),
        "metricas": {
            "tempo_execucao": round(duracao, 2),
            "prompt_tokens": contar_tokens(prompt_en),
            "resposta_tokens": contar_tokens(resposta_en),
            "palavras_chave_comuns": num_keywords,
            "validacao_keywords": valido
        },
        "scores": [{"doc": trecho.page_content, "score": float(score)} for trecho, score in scores],
        "caminhos_de_gravacao": {
            "historico": "data/respostas/velvet_respostas.json",
            "ultima_resposta": "data/respostas/velvet_ultima_resposta.json"
        },
        "resposta_pt": resposta_final,
        "data": datetime.now().isoformat()
    })
    print(f"\nâœ… [DEBUG] Resposta final traduzida (PT):\n{resposta_final}\n")
    return {
        "resposta_pt": resposta_final,
        "tempo_execucao": round(duracao, 2),
        "resposta_tokens": contar_tokens(resposta_en),
        "validacao_keywords": valido
    }
